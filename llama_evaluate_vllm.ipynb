{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.1.0\n",
        "!pip install spacy\n",
        "!pip install vllm\n",
        "!pip install kaleido python-multipart typing-extensions\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgXaTXjUgytW",
        "outputId": "bb8f8278-83c0-44cb-d2ca-bcaa32537d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting vllm\n",
            "  Downloading vllm-0.4.0.post1-cp310-cp310-manylinux1_x86_64.whl (97.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cmake>=3.21 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.27.9)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n",
            "Collecting ray>=2.9 (from vllm)\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vllm) (1.23.5)\n",
            "Collecting torch==2.1.2 (from vllm)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vllm) (2.31.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n",
            "Collecting transformers>=4.39.1 (from vllm)\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xformers==0.0.23.post1 (from vllm)\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from vllm)\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard] (from vllm)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.6.0)\n",
            "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.19.0)\n",
            "Collecting pynvml==11.5.0 (from vllm)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.1.0)\n",
            "Collecting outlines==0.0.34 (from vllm)\n",
            "  Downloading outlines-0.0.34-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken==0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting interegular (from outlines==0.0.34->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (3.1.3)\n",
            "Collecting lark (from outlines==0.0.34->vllm)\n",
            "  Downloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (2.2.1)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (5.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (1.11.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (0.58.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (1.3.2)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (0.33.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from outlines==0.0.34->vllm) (4.19.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.6.0->vllm) (2023.12.25)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->vllm) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->vllm) (2.16.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (23.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vllm) (2024.2.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.1->vllm) (0.20.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.1->vllm) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.1->vllm) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.1->vllm) (4.66.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->vllm)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn[standard]->vllm)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi->vllm) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->outlines==0.0.34->vllm) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->outlines==0.0.34->vllm) (2023.12.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->outlines==0.0.34->vllm) (0.17.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines==0.0.34->vllm) (0.41.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.2.0)\n",
            "Installing collected packages: ninja, websockets, uvloop, python-dotenv, pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lark, interegular, httptools, h11, watchfiles, uvicorn, tiktoken, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, fastapi, transformers, torch, ray, xformers, outlines, vllm\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.110.1 h11-0.14.0 httptools-0.6.1 interegular-0.3.3 lark-1.1.9 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 outlines-0.0.34 pynvml-11.5.0 python-dotenv-1.0.1 ray-2.10.0 starlette-0.37.2 tiktoken-0.6.0 torch-2.1.2 transformers-4.39.3 uvicorn-0.29.0 uvloop-0.19.0 vllm-0.4.0.post1 watchfiles-0.21.0 websockets-12.0 xformers-0.0.23.post1\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.9.0)\n",
            "Installing collected packages: kaleido, python-multipart\n",
            "Successfully installed kaleido-0.2.1 python-multipart-0.0.9\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from spacy.lang.en import English\n",
        "from huggingface_hub import login\n",
        "from vllm import LLM, SamplingParams\n",
        "import transformers\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "access_token = \"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\"\n",
        "\n",
        "\n",
        "login(token=access_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqFoOvsMg09n",
        "outputId": "bcb98b1e-0126-4e00-8bd6-a2807e50c3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: read).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = LLM(model=model_name, gpu_memory_utilization=0.9)"
      ],
      "metadata": {
        "id": "Ose0fx17g1Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlVyknMhy3-Z"
      },
      "outputs": [],
      "source": [
        "nlp = English()\n",
        "english_tokenizer = nlp.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onkWVfe0y3-Z"
      },
      "outputs": [],
      "source": [
        "pii_labels = ['NAME_STUDENT', 'EMAIL', 'USERNAME', 'ID_NUM', 'PHONE_NUM', 'URL_PERSONAL', 'STREET_ADDRESS']\n",
        "pii_labels_pattern = '|'.join(pii_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_Zb9RhLy3-a"
      },
      "outputs": [],
      "source": [
        "def find_sequence_indices(list_words, sequence_to_find):\n",
        "    sequence_length = len(sequence_to_find)\n",
        "    indices = [i for i in range(len(list_words) - sequence_length + 1) if list_words[i:i+sequence_length] == sequence_to_find]\n",
        "    return indices\n",
        "\n",
        "def llama_to_tokens(output):\n",
        "    nlp = English()\n",
        "\n",
        "    english_tokenizer = nlp.tokenizer\n",
        "\n",
        "    tokens = []\n",
        "    labels = []\n",
        "\n",
        "    answers = re.split(r'\\n',output)\n",
        "    for i in range(len(answers)):\n",
        "        tokens.append(re.split(r'\\(|\\)', answers[i])[:-1])\n",
        "        labels.append(tokens[-1][-1])\n",
        "        tokens[-1] = tokens[-1][:-1]\n",
        "\n",
        "    # print('Tokens', tokens)\n",
        "    # print('Labels', labels)\n",
        "    for i in range(len(tokens)):\n",
        "        # print(tokens[i][0])\n",
        "        tokenized = english_tokenizer(tokens[i][0])\n",
        "        tokens[i] = [i.text for i in tokenized]\n",
        "\n",
        "    return tokens, labels\n",
        "\n",
        "def categorizer(full_token_list, llm_tokens, labels):\n",
        "    indices = []\n",
        "    for i in range(len(llm_tokens)):\n",
        "        indices.append(find_sequence_indices(full_token_list, llm_tokens[i]))\n",
        "    # print(\"Indices\", indices)\n",
        "    result = ['O'] * len(full_token_list) # This will be a list of length full_tokens_list\n",
        "\n",
        "    for k in range(len(llm_tokens)):\n",
        "        for i in range(len(indices[k])):\n",
        "            result[indices[k][i]] = 'B-'+labels[k]\n",
        "            if len(llm_tokens[k])>1:\n",
        "                for l in range(len(llm_tokens[k])-1):\n",
        "                    result[indices[k][i]+l+1] = 'I-' + labels[k]\n",
        "\n",
        "    return result[:len(full_token_list)]\n",
        "\n",
        "def assign_labels(full_text, output_text):\n",
        "    # print('full_text:',full_text)\n",
        "    tokenized = english_tokenizer(full_text)\n",
        "    full_text_tokens = [i.text for i in tokenized]\n",
        "    # print(\"Full Text Tokens:\", full_text_tokens)\n",
        "    # print('LLM Output:', output_text)\n",
        "\n",
        "    text_tokens, labels = llama_to_tokens(output_text)\n",
        "    # print('Text tokens:',text_tokens,'Labels:',labels)\n",
        "\n",
        "    labeled_output = categorizer(full_text_tokens,text_tokens, labels)\n",
        "    # print('Final Output:', labeled_output)\n",
        "    return labeled_output\n",
        "\n",
        "def curate_labels(labeled_tokens):\n",
        "    label_pattern = pii_labels_pattern + \"|O\"\n",
        "\n",
        "    for i in range(len(labeled_tokens)):\n",
        "        if(not re.search(label_pattern, labeled_tokens[i])):\n",
        "            labeled_tokens[i] = 'O'\n",
        "\n",
        "def get_batches(text, max_length = 400):\n",
        "  inputs = []\n",
        "  labels = []\n",
        "  for j in range(0, len(data[\"tokens\"]), max_length):\n",
        "      batch_size = min(j + max_length, len(data[\"tokens\"]))\n",
        "      input_text = \" \".join(data[\"tokens\"][j: batch_size])\n",
        "      output_labels = data[\"labels\"][j: batch_size]\n",
        "      inputs.append(input_text)\n",
        "      labels.append(output_labels)\n",
        "\n",
        "  return (inputs, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSrduhVi4ntE"
      },
      "outputs": [],
      "source": [
        "def format_prompt(prompt: str):\n",
        "    return f'''<s>[INST] <<SYS>>\n",
        "You are a helpful and honest assistant.\n",
        "<</SYS>>\n",
        "\n",
        "You are searching for these different types of information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student’s email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of information and which type of information it is.\n",
        "\n",
        "TEXT:\n",
        "My name is Bryce and my sister's name is Sara. My email is tombombadill@gmail.com and my contact number is 830 688 0393.\n",
        "OUTPUT:\n",
        "[/INST]\n",
        "Bryce (NAME_STUDENT),\n",
        "Sara (NAME_STUDENT),\n",
        "tombombadill@gmail.com (EMAIL),\n",
        "830 688 0393 (PHONE_NUM)\n",
        "</s>\n",
        "<s>[INST]\n",
        "You are searching for these different types of information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student's email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of information belonging to the previous types and which type they are.\n",
        "\n",
        "TEXT:\n",
        "John Doe , I live in the 123 Main Street. My website is www.seanhalpin.xyz and my contact number is 888-688-5461.\n",
        "OUTPUT:\n",
        "[/INST]\n",
        "John Doe (NAME_STUDENT),\n",
        "123 Main Street (STREET_ADDRESS),\n",
        "www.seanhalpin.xyz (URL_PERSONAL),\n",
        "830-688-0393 (PHONE_NUM)\n",
        "</s>\n",
        "<s>[INST]\n",
        "You are searching for these different types of information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student's email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of information belonging to the previous type and which type they are.\n",
        "\n",
        "TEXT:\n",
        "The hallways of Greenwood High, everyone knew that if you needed help with calculus, you would look for Jamie Turner whose ID is GHS20241015. She known to have a knack for numbers.\n",
        "OUTPUT:\n",
        "[/INST]\n",
        "Jamie Turner (NAME_STUDENT),\n",
        "GHS20241015 (ID_NUM)\n",
        "</s>\n",
        "<s>[INST]\n",
        "You are searching for these different types of information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student's email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of information belonging to the previous type and which type they are.\n",
        "Please, format the list in the following format:\n",
        "<information> (<TYPE>),\n",
        "<information> (<TYPE>)\n",
        "\n",
        "TEXT:\n",
        "{prompt}\n",
        "OUTPUT:\n",
        "[/INST]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0jJfe6WZRWL"
      },
      "outputs": [],
      "source": [
        "def format_prompt(prompt: str):\n",
        "    return f'''<s>[INST]\n",
        "You are searching for these different types of personal identifiable information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student’s email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
        "Please, format the list in the following format:\n",
        "<personal identifiable information> (<INFORMATION_TYPE>),\n",
        "<personal identifiable information> (<INFORMATION_TYPE>)\n",
        "\n",
        "TEXT:\n",
        "My name is Bryce and my sister's name is Sara. My email is tombombadill@gmail.com and my contact number is 830 688 0393.\n",
        "OUTPUT:\n",
        "Bryce (NAME_STUDENT),\n",
        "Sara (NAME_STUDENT),\n",
        "tombombadill@gmail.com (EMAIL),\n",
        "830 688 0393 (PHONE_NUM)\n",
        "\n",
        "You are searching for these different types of personal identifiable information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student's email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
        "Please, format the list in the following format:\n",
        "<personal identifiable information> (<INFORMATION_TYPE>),\n",
        "<personal identifiable information> (<INFORMATION_TYPE>)\n",
        "\n",
        "TEXT:\n",
        "John Doe , I live in the 123 Main Street. My website is www.seanhalpin.xyz and my contact number is 888-688-5461.\n",
        "OUTPUT:\n",
        "John Doe (NAME_STUDENT),\n",
        "123 Main Street (STREET_ADDRESS),\n",
        "www.seanhalpin.xyz (URL_PERSONAL),\n",
        "830-688-0393 (PHONE_NUM)\n",
        "\n",
        "You are searching for these different types of personal identifiable information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student's email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
        "Please, format the list in the following format:\n",
        "<personal identifiable information> (<INFORMATION_TYPE>),\n",
        "<personal identifiable information> (<INFORMATION_TYPE>)\n",
        "\n",
        "TEXT:\n",
        "{prompt}\n",
        "OUTPUT:\n",
        "[/INST]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjLFow99YWLb"
      },
      "outputs": [],
      "source": [
        "def format_prompt(prompt: str):\n",
        "    return f'''<s>[INST]\n",
        "You are searching for these different types of personal identifiable information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student’s email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
        "Please, format the list in the following format:\n",
        "Please, format the list in the following format:\n",
        "<personal identifiable information> (<INFORMATION_TYPE>),\n",
        "<personal identifiable information> (<INFORMATION_TYPE>)\n",
        "\n",
        "TEXT:\n",
        "My name is Bryce and my sister's name is Sara. My email is tombombadill@gmail.com and my contact number is 830 688 0393.\n",
        "OUTPUT:\n",
        "[/INST]\n",
        "Bryce (NAME_STUDENT),\n",
        "Sara (NAME_STUDENT),\n",
        "tombombadill@gmail.com (EMAIL),\n",
        "830 688 0393 (PHONE_NUM)\n",
        "</s>\n",
        "<s>[INST]\n",
        "You are searching for these different types of personal identifiable information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student's email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
        "Please, format the list in the following format:\n",
        "<personal identifiable information> (<INFORMATION_TYPE>),\n",
        "<personal identifiable information> (<INFORMATION_TYPE>)\n",
        "\n",
        "TEXT:\n",
        "John Doe , I live in the 123 Main Street. My website is www.seanhalpin.xyz and my contact number is 888-688-5461.\n",
        "OUTPUT:\n",
        "[/INST]\n",
        "John Doe (NAME_STUDENT),\n",
        "123 Main Street (STREET_ADDRESS),\n",
        "www.seanhalpin.xyz (URL_PERSONAL),\n",
        "830-688-0393 (PHONE_NUM)\n",
        "</s>\n",
        "<s>[INST]\n",
        "You are searching for these different types of personal identifiable information:\n",
        "\n",
        "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
        "EMAIL - A student's email address.\n",
        "USERNAME - A student's username on any platform.\n",
        "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
        "PHONE_NUM - A phone number associated with a student.\n",
        "URL_PERSONAL - A URL that might be used to identify a student.\n",
        "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
        "\n",
        "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
        "Your OUTPUT should have the following format:\n",
        "<personal identifiable information> (<INFORMATION_TYPE>),\n",
        "<personal identifiable information> (<INFORMATION_TYPE>)\n",
        "\n",
        "TEXT:\n",
        "{prompt}\n",
        "OUTPUT:\n",
        "[/INST]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-yo0_YQy3-a"
      },
      "outputs": [],
      "source": [
        "train_data_path = \"pii-detection-data/train.json\"\n",
        "test_data_path = \"pii-detection-data/test.json\"\n",
        "\n",
        "# Loading Dataset\n",
        "with open(train_data_path) as file:\n",
        "    train_data_json = json.load(file)\n",
        "    print(\"Training Data: \", len(train_data_json))\n",
        "\n",
        "with open(test_data_path ) as file:\n",
        "    test_data_json = json.load(file)\n",
        "    print(\"Test Data: \", len(test_data_json))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8sVj8Lwy3-a"
      },
      "outputs": [],
      "source": [
        "# Limiting the data for testing\n",
        "train_data_size = int(len(train_data_json) * 0.002)\n",
        "print(\"Train Data Size: \", train_data_size)\n",
        "\n",
        "train_data = train_data_json[:train_data_size]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \" \".join(train_data[0][\"tokens\"][:400])\n",
        "format_prompt(input_text)"
      ],
      "metadata": {
        "id": "Y9P8u_NT1Aec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting Hyperparameters\n",
        "sampling_params = SamplingParams(temperature=0, max_tokens=2048)"
      ],
      "metadata": {
        "id": "6rfQBrESR-D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Input\n",
        "input_text = \" \".join(train_data[0][\"tokens\"][400:])\n",
        "input_text"
      ],
      "metadata": {
        "id": "TdGuEF5mMjfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Model\n",
        "outputs = llm.generate(\n",
        "    [format_prompt(input_text)],\n",
        "    sampling_params\n",
        "    )\n",
        "\n",
        "# Print the outputs.\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print()\n",
        "    print(\"Generated text:\\n\", generated_text)"
      ],
      "metadata": {
        "id": "QRQ7jFHYztXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = re.split(r',?\\n', generated_text)\n",
        "print(outputs)\n",
        "outputs = [output.strip() for output in outputs if re.search(f\"\\S+\\s?\\(({pii_labels_pattern})\\)\", output)]\n",
        "print(\"List of PII:\\n\", outputs)"
      ],
      "metadata": {
        "id": "d4dZ55Lz61H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_input_ids = []\n",
        "train_labels_input_ids = []\n",
        "max_length = 400\n",
        "total_classifications = 0\n",
        "num_misclassified = 0\n",
        "num_hallucinated = 0\n",
        "\n",
        "try:\n",
        "    for i, data in enumerate(train_data):\n",
        "        print(\"Processing Sample:\", i)\n",
        "        # Loop through data in batches of 400 tokens\n",
        "        inputs, labels = get_batches(data)\n",
        "        print(\"Number of Text Splits:\", len(inputs))\n",
        "\n",
        "        model_outputs = llm.generate(\n",
        "            [format_prompt(input) for input in inputs],\n",
        "            sampling_params\n",
        "            )\n",
        "        print()\n",
        "\n",
        "        # Print the outputs.\n",
        "        for input_text, output_labels, model_output in zip(inputs, labels, model_outputs):\n",
        "            generated_text = model_output.outputs[0].text\n",
        "\n",
        "            # Process output text\n",
        "            outputs = re.split(r',?\\n', generated_text)\n",
        "            outputs = [output.strip() for output in outputs if re.search(f\"\\S+\\s?\\(({pii_labels_pattern})\\)\", output)]\n",
        "            print(\"List of PII:\\n\", outputs)\n",
        "\n",
        "            expected_labels = len(output_labels) - output_labels.count('O')\n",
        "            total_classifications += expected_labels\n",
        "\n",
        "            if(not outputs):\n",
        "                num_misclassified += expected_labels\n",
        "                print('Invalid Output:')\n",
        "                print(\"Input:\\n\", input_text)\n",
        "                print(\"Generated Text:\\n\", generated_text)\n",
        "                print(\"Labels:\\n\", output_labels)\n",
        "\n",
        "                continue\n",
        "\n",
        "            output_text = '\\n'.join(outputs)\n",
        "\n",
        "            # Assigning Labels\n",
        "            labeled_output = assign_labels(input_text, output_text)\n",
        "            curate_labels(labeled_output)\n",
        "\n",
        "            print(\"Input:\\n\", input_text)\n",
        "            print(\"Generated Text:\\n\", generated_text)\n",
        "            print(\"Labels:\\n\", output_labels)\n",
        "            print(\"Output:\\n\", labeled_output)\n",
        "\n",
        "            assert len(output_labels) == len(labeled_output)\n",
        "\n",
        "            # Comparing output with expected labels\n",
        "            for i in range(len(labeled_output)):\n",
        "                if(labeled_output[i] == output_labels[i]):\n",
        "                  continue\n",
        "\n",
        "                if(output_labels[i] == 'O'):\n",
        "                    num_hallucinated += 1\n",
        "                    num_misclassified += 1\n",
        "                    total_classifications += 1\n",
        "                else:\n",
        "                    num_misclassified += 1\n",
        "\n",
        "            print(\"Number Hallucinated:\", num_hallucinated)\n",
        "            print(\"Total Missclassified:\", num_misclassified)\n",
        "\n",
        "        print()\n",
        "        print(\"Misclassification:\", num_misclassified / total_classifications)\n",
        "        print(\"Accuracy:\", (total_classifications - num_misclassified) / total_classifications)\n",
        "        print(\"Accuracy Excluding Hallucinations:\", (total_classifications - num_misclassified) / (total_classifications - num_hallucinated))\n",
        "        print()\n",
        "\n",
        "except Exception as error:\n",
        "    print(\"\\nError Occured for the following input:\")\n",
        "    print(\"INPUT:\", input_text)\n",
        "    print(\"EXPECTED OUTPUT:\", output_labels)\n",
        "    print(\"GENERATED TEXT:\", generated_text)\n",
        "    print(\"PROCESSED OUTPUT:\", outputs)\n",
        "    print(\"LABELED OUTPUT:\", labeled_output)\n",
        "    print(\"ERROR:\", error)\n"
      ],
      "metadata": {
        "id": "U7Uz3DoD-el2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}