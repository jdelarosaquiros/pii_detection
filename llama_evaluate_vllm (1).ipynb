{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# !pip install torch==2.1.0\n",
    "!pip install spacy\n",
    "!pip install vllm\n",
    "!pip install kaleido python-multipart typing-extensions\n",
    "!pip install huggingface_hub"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgXaTXjUgytW",
    "outputId": "bb8f8278-83c0-44cb-d2ca-bcaa32537d7a",
    "ExecuteTime": {
     "end_time": "2024-04-23T15:54:05.147011600Z",
     "start_time": "2024-04-23T15:54:00.056280600Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: spacy in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (3.7.4)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (8.2.3)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (0.9.4)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (6.4.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from spacy) (4.65.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from spacy) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (2.7.0)\r\n",
      "Requirement already satisfied: jinja2 in /home/brycelinux/.local/lib/python3.10/site-packages (from spacy) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (69.5.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from spacy) (23.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from spacy) (3.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from spacy) (1.23.5)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/brycelinux/.local/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: vllm in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (0.4.0.post1)\r\n",
      "Requirement already satisfied: cmake>=3.21 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (3.29.2)\r\n",
      "Requirement already satisfied: ninja in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (1.11.1.1)\r\n",
      "Requirement already satisfied: psutil in /home/brycelinux/.local/lib/python3.10/site-packages (from vllm) (5.9.5)\r\n",
      "Requirement already satisfied: ray>=2.9 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (2.10.0)\r\n",
      "Requirement already satisfied: sentencepiece in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (0.2.0)\r\n",
      "Requirement already satisfied: numpy in /home/brycelinux/.local/lib/python3.10/site-packages (from vllm) (1.23.5)\r\n",
      "Requirement already satisfied: torch==2.1.2 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (2.1.2)\r\n",
      "Requirement already satisfied: requests in /home/brycelinux/.local/lib/python3.10/site-packages (from vllm) (2.31.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (9.0.0)\r\n",
      "Requirement already satisfied: transformers>=4.39.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (4.39.3)\r\n",
      "Requirement already satisfied: xformers==0.0.23.post1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (0.0.23.post1)\r\n",
      "Requirement already satisfied: fastapi in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (0.110.1)\r\n",
      "Requirement already satisfied: uvicorn[standard] in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (0.29.0)\r\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (2.7.0)\r\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (0.20.0)\r\n",
      "Requirement already satisfied: pynvml==11.5.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (11.5.0)\r\n",
      "Requirement already satisfied: triton>=2.1.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (2.1.0)\r\n",
      "Requirement already satisfied: outlines==0.0.34 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (0.0.34)\r\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from vllm) (0.6.0)\r\n",
      "Requirement already satisfied: interegular in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/brycelinux/.local/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (3.1.2)\r\n",
      "Requirement already satisfied: lark in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.1.9)\r\n",
      "Requirement already satisfied: nest-asyncio in /home/brycelinux/.local/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.5.6)\r\n",
      "Requirement already satisfied: cloudpickle in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (3.0.0)\r\n",
      "Requirement already satisfied: diskcache in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (5.6.3)\r\n",
      "Requirement already satisfied: scipy in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.13.0)\r\n",
      "Requirement already satisfied: numba in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.59.1)\r\n",
      "Requirement already satisfied: joblib in /home/brycelinux/.local/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.3.1)\r\n",
      "Requirement already satisfied: referencing in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.34.0)\r\n",
      "Requirement already satisfied: jsonschema in /home/brycelinux/.local/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (4.17.3)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/brycelinux/.local/lib/python3.10/site-packages (from tiktoken==0.6.0->vllm) (2023.6.3)\r\n",
      "Requirement already satisfied: filelock in /home/brycelinux/.local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (4.10.0)\r\n",
      "Requirement already satisfied: sympy in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (1.12)\r\n",
      "Requirement already satisfied: networkx in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.2.1)\r\n",
      "Requirement already satisfied: fsspec in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (2024.2.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm) (12.3.101)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (2.18.1)\r\n",
      "Requirement already satisfied: click>=7.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from ray>=2.9->vllm) (8.1.3)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.0.5)\r\n",
      "Requirement already satisfied: packaging in /home/brycelinux/.local/lib/python3.10/site-packages (from ray>=2.9->vllm) (23.1)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from ray>=2.9->vllm) (5.26.1)\r\n",
      "Requirement already satisfied: pyyaml in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from ray>=2.9->vllm) (6.0.1)\r\n",
      "Requirement already satisfied: aiosignal in /home/brycelinux/.local/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /home/brycelinux/.local/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.3.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests->vllm) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests->vllm) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests->vllm) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests->vllm) (2023.5.7)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.21.1)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/brycelinux/.local/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (4.65.0)\r\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from fastapi->vllm) (0.37.2)\r\n",
      "Requirement already satisfied: h11>=0.8 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.14.0)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (1.0.1)\r\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.21.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (12.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from starlette<0.38.0,>=0.37.2->fastapi->vllm) (3.7.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from jinja2->outlines==0.0.34->vllm) (2.1.3)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/brycelinux/.local/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (0.19.3)\r\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from numba->outlines==0.0.34->vllm) (0.42.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from referencing->outlines==0.0.34->vllm) (0.18.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/brycelinux/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup in /home/brycelinux/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.1.2)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: kaleido in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (0.2.1)\r\n",
      "Requirement already satisfied: python-multipart in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (0.0.9)\r\n",
      "Requirement already satisfied: typing-extensions in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (4.10.0)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: huggingface_hub in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (0.21.1)\r\n",
      "Requirement already satisfied: filelock in /home/brycelinux/.local/lib/python3.10/site-packages (from huggingface_hub) (3.12.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\r\n",
      "Requirement already satisfied: requests in /home/brycelinux/.local/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/brycelinux/.local/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/brycelinux/miniconda3/envs/PII/lib/python3.10/site-packages (from huggingface_hub) (4.10.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /home/brycelinux/.local/lib/python3.10/site-packages (from huggingface_hub) (23.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/brycelinux/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.5.7)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "from spacy.lang.en import English\n",
    "from huggingface_hub import login\n",
    "from vllm import LLM, SamplingParams\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "model_name = \"javijer/llama2_custom_pii_13b\"\n",
    "access_token = \"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\"\n",
    "\n",
    "\n",
    "login(token=access_token, add_to_git_credential=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqFoOvsMg09n",
    "outputId": "bcb98b1e-0126-4e00-8bd6-a2807e50c3d6",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:24:13.681426300Z",
     "start_time": "2024-04-23T16:24:11.964130500Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "\u001B[1m\u001B[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001B[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/brycelinux/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "llm = LLM(model=model_name, gpu_memory_utilization=0.99, dtype='bfloat16', max_model_len= 1300)"
   ],
   "metadata": {
    "id": "Ose0fx17g1Gp",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:13.049427300Z",
     "start_time": "2024-04-23T16:24:17.742429900Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-23 11:24:17 config.py:767] Casting torch.float16 to torch.bfloat16.\n",
      "INFO 04-23 11:24:17 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='javijer/llama2_custom_pii_13b', tokenizer='javijer/llama2_custom_pii_13b', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1300, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "WARNING 04-23 11:24:18 utils.py:357] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 04-23 11:24:18 selector.py:16] Using FlashAttention backend.\n",
      "INFO 04-23 11:24:19 weight_utils.py:177] Using model weights format ['*.safetensors']\n",
      "INFO 04-23 11:24:23 model_runner.py:104] Loading model weights took 24.2840 GB\n",
      "INFO 04-23 11:24:36 gpu_executor.py:94] # GPU blocks: 104, # CPU blocks: 327\n",
      "INFO 04-23 11:24:36 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-23 11:24:36 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-23 11:25:12 model_runner.py:867] Graph capturing finished in 36 secs.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TlVyknMhy3-Z",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:15.490446200Z",
     "start_time": "2024-04-23T16:25:15.398315600Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "english_tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "onkWVfe0y3-Z",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:15.591666700Z",
     "start_time": "2024-04-23T16:25:15.584393200Z"
    }
   },
   "outputs": [],
   "source": [
    "pii_labels = ['NAME_STUDENT', 'EMAIL', 'USERNAME', 'ID_NUM', 'PHONE_NUM', 'URL_PERSONAL', 'STREET_ADDRESS']\n",
    "pii_labels_pattern = '|'.join(pii_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z_Zb9RhLy3-a",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:15.942417700Z",
     "start_time": "2024-04-23T16:25:15.938909400Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_sequence_indices(list_words, sequence_to_find):\n",
    "    sequence_length = len(sequence_to_find)\n",
    "    indices = [i for i in range(len(list_words) - sequence_length + 1) if list_words[i:i+sequence_length] == sequence_to_find]\n",
    "    return indices\n",
    "\n",
    "def llama_to_tokens(output):\n",
    "    nlp = English()\n",
    "\n",
    "    english_tokenizer = nlp.tokenizer\n",
    "\n",
    "    tokens = []\n",
    "    labels = []\n",
    "\n",
    "    answers = re.split(r'\\n',output)\n",
    "    for i in range(len(answers)):\n",
    "        tokens.append(re.split(r'\\(|\\)', answers[i])[:-1])\n",
    "        labels.append(tokens[-1][-1])\n",
    "        tokens[-1] = tokens[-1][:-1]\n",
    "\n",
    "    # print('Tokens', tokens)\n",
    "    # print('Labels', labels)\n",
    "    for i in range(len(tokens)):\n",
    "        # print(tokens[i][0])\n",
    "        tokenized = english_tokenizer(tokens[i][0])\n",
    "        tokens[i] = [i.text for i in tokenized]\n",
    "\n",
    "    return tokens, labels\n",
    "\n",
    "def categorizer(full_token_list, llm_tokens, labels):\n",
    "    indices = []\n",
    "    for i in range(len(llm_tokens)):\n",
    "        indices.append(find_sequence_indices(full_token_list, llm_tokens[i]))\n",
    "    # print(\"Indices\", indices)\n",
    "    result = ['O'] * len(full_token_list) # This will be a list of length full_tokens_list\n",
    "\n",
    "    for k in range(len(llm_tokens)):\n",
    "        for i in range(len(indices[k])):\n",
    "            result[indices[k][i]] = 'B-'+labels[k]\n",
    "            if len(llm_tokens[k])>1:\n",
    "                for l in range(len(llm_tokens[k])-1):\n",
    "                    result[indices[k][i]+l+1] = 'I-' + labels[k]\n",
    "\n",
    "    return result[:len(full_token_list)]\n",
    "\n",
    "def assign_labels(full_text, output_text):\n",
    "    # print('full_text:',full_text)\n",
    "    tokenized = english_tokenizer(full_text)\n",
    "    full_text_tokens = [i.text for i in tokenized]\n",
    "    # print(\"Full Text Tokens:\", full_text_tokens)\n",
    "    # print('LLM Output:', output_text)\n",
    "\n",
    "    text_tokens, labels = llama_to_tokens(output_text)\n",
    "    # print('Text tokens:',text_tokens,'Labels:',labels)\n",
    "\n",
    "    labeled_output = categorizer(full_text_tokens,text_tokens, labels)\n",
    "    # print('Final Output:', labeled_output)\n",
    "    return labeled_output\n",
    "\n",
    "def curate_labels(labeled_tokens):\n",
    "    label_pattern = pii_labels_pattern + \"|O\"\n",
    "\n",
    "    for i in range(len(labeled_tokens)):\n",
    "        if(not re.search(label_pattern, labeled_tokens[i])):\n",
    "            labeled_tokens[i] = 'O'\n",
    "\n",
    "def get_batches(text, max_length = 400):\n",
    "  inputs = []\n",
    "  labels = []\n",
    "  for j in range(0, len(data[\"tokens\"]), max_length):\n",
    "      batch_size = min(j + max_length, len(data[\"tokens\"]))\n",
    "      input_text = \" \".join(data[\"tokens\"][j: batch_size])\n",
    "      output_labels = data[\"labels\"][j: batch_size]\n",
    "      inputs.append(input_text)\n",
    "      labels.append(output_labels)\n",
    "\n",
    "  return (inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PSrduhVi4ntE",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:18.734536900Z",
     "start_time": "2024-04-23T16:25:18.680841500Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_prompt(prompt: str):\n",
    "    return f'''<s>[INST] <<SYS>>\n",
    "You are a helpful and honest assistant.\n",
    "<</SYS>>\n",
    "\n",
    "You are searching for these different types of information:\n",
    "\n",
    "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
    "EMAIL - A student’s email address.\n",
    "USERNAME - A student's username on any platform.\n",
    "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
    "PHONE_NUM - A phone number associated with a student.\n",
    "URL_PERSONAL - A URL that might be used to identify a student.\n",
    "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
    "\n",
    "You will be given a TEXT, and your OUTPUT will be a list of each instance of information and which type of information it is.\n",
    "\n",
    "TEXT:\n",
    "My name is Bryce and my sister's name is Sara. My email is tombombadill@gmail.com and my contact number is 830 688 0393.\n",
    "OUTPUT:\n",
    "[/INST]\n",
    "Bryce (NAME_STUDENT),\n",
    "Sara (NAME_STUDENT),\n",
    "tombombadill@gmail.com (EMAIL),\n",
    "830 688 0393 (PHONE_NUM)\n",
    "</s>\n",
    "<s>[INST]\n",
    "You are searching for these different types of information:\n",
    "\n",
    "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
    "EMAIL - A student's email address.\n",
    "USERNAME - A student's username on any platform.\n",
    "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
    "PHONE_NUM - A phone number associated with a student.\n",
    "URL_PERSONAL - A URL that might be used to identify a student.\n",
    "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
    "\n",
    "You will be given a TEXT, and your OUTPUT will be a list of each instance of information belonging to the previous types and which type they are.\n",
    "\n",
    "TEXT:\n",
    "John Doe , I live in the 123 Main Street. My website is www.seanhalpin.xyz and my contact number is 888-688-5461.\n",
    "OUTPUT:\n",
    "[/INST]\n",
    "John Doe (NAME_STUDENT),\n",
    "123 Main Street (STREET_ADDRESS),\n",
    "www.seanhalpin.xyz (URL_PERSONAL),\n",
    "830-688-0393 (PHONE_NUM)\n",
    "</s>\n",
    "<s>[INST]\n",
    "You are searching for these different types of information:\n",
    "\n",
    "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
    "EMAIL - A student's email address.\n",
    "USERNAME - A student's username on any platform.\n",
    "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
    "PHONE_NUM - A phone number associated with a student.\n",
    "URL_PERSONAL - A URL that might be used to identify a student.\n",
    "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
    "\n",
    "You will be given a TEXT, and your OUTPUT will be a list of each instance of information belonging to the previous type and which type they are.\n",
    "\n",
    "TEXT:\n",
    "The hallways of Greenwood High, everyone knew that if you needed help with calculus, you would look for Jamie Turner whose ID is GHS20241015. She known to have a knack for numbers.\n",
    "OUTPUT:\n",
    "[/INST]\n",
    "Jamie Turner (NAME_STUDENT),\n",
    "GHS20241015 (ID_NUM)\n",
    "</s>\n",
    "<s>[INST]\n",
    "You are searching for these different types of information:\n",
    "\n",
    "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
    "EMAIL - A student's email address.\n",
    "USERNAME - A student's username on any platform.\n",
    "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
    "PHONE_NUM - A phone number associated with a student.\n",
    "URL_PERSONAL - A URL that might be used to identify a student.\n",
    "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
    "\n",
    "You will be given a TEXT, and your OUTPUT will be a list of each instance of information belonging to the previous type and which type they are.\n",
    "Please, format the list in the following format:\n",
    "<information> (<TYPE>),\n",
    "<information> (<TYPE>)\n",
    "\n",
    "TEXT:\n",
    "{prompt}\n",
    "OUTPUT:\n",
    "[/INST]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w0jJfe6WZRWL",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:18.898125200Z",
     "start_time": "2024-04-23T16:25:18.893617400Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_prompt(prompt: str):\n",
    "    return f'''<s>[INST]\n",
    "You are searching for these different types of personal identifiable information:\n",
    "\n",
    "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
    "EMAIL - A student’s email address.\n",
    "USERNAME - A student's username on any platform.\n",
    "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
    "PHONE_NUM - A phone number associated with a student.\n",
    "URL_PERSONAL - A URL that might be used to identify a student.\n",
    "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
    "\n",
    "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
    "Please, format the list in the following format:\n",
    "<personal identifiable information> (<INFORMATION_TYPE>),\n",
    "<personal identifiable information> (<INFORMATION_TYPE>)\n",
    "\n",
    "TEXT:\n",
    "My name is Bryce and my sister's name is Sara. My email is tombombadill@gmail.com and my contact number is 830 688 0393.\n",
    "OUTPUT:\n",
    "Bryce (NAME_STUDENT),\n",
    "Sara (NAME_STUDENT),\n",
    "tombombadill@gmail.com (EMAIL),\n",
    "830 688 0393 (PHONE_NUM)\n",
    "\n",
    "You are searching for these different types of personal identifiable information:\n",
    "\n",
    "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
    "EMAIL - A student's email address.\n",
    "USERNAME - A student's username on any platform.\n",
    "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
    "PHONE_NUM - A phone number associated with a student.\n",
    "URL_PERSONAL - A URL that might be used to identify a student.\n",
    "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
    "\n",
    "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
    "Please, format the list in the following format:\n",
    "<personal identifiable information> (<INFORMATION_TYPE>),\n",
    "<personal identifiable information> (<INFORMATION_TYPE>)\n",
    "\n",
    "TEXT:\n",
    "John Doe , I live in the 123 Main Street. My website is www.seanhalpin.xyz and my contact number is 888-688-5461.\n",
    "OUTPUT:\n",
    "John Doe (NAME_STUDENT),\n",
    "123 Main Street (STREET_ADDRESS),\n",
    "www.seanhalpin.xyz (URL_PERSONAL),\n",
    "830-688-0393 (PHONE_NUM)\n",
    "\n",
    "You are searching for these different types of personal identifiable information:\n",
    "\n",
    "NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.\n",
    "EMAIL - A student's email address.\n",
    "USERNAME - A student's username on any platform.\n",
    "ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.\n",
    "PHONE_NUM - A phone number associated with a student.\n",
    "URL_PERSONAL - A URL that might be used to identify a student.\n",
    "STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.\n",
    "\n",
    "You will be given a TEXT, and your OUTPUT will be a list of each instance of personal identifiable information and its type.\n",
    "Please, format the list in the following format:\n",
    "<personal identifiable information> (<INFORMATION_TYPE>),\n",
    "<personal identifiable information> (<INFORMATION_TYPE>)\n",
    "\n",
    "TEXT:\n",
    "{prompt}\n",
    "OUTPUT:\n",
    "[/INST]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hjLFow99YWLb",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:19.733032600Z",
     "start_time": "2024-04-23T16:25:19.727927200Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_prompt(text: str, answer: str = ''):\n",
    "    return f'''<s>[INST] You are a helpful and honest assistant trained to identify and categorize Personally Identifiable Information in a given text. You are searching for these different types of Personally Identifiable Information:\n",
    "\n",
    "The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names (NAME_STUDENT),\n",
    "The email address of a student (EMAIL),\n",
    "The username of a student on any platform (USERNAME),\n",
    "A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number (ID_NUM),\n",
    "A phone number associated with a student (PHONE_NUM),\n",
    "A URL that might be used to identify a student (URL_PERSONAL),\n",
    "A full or partial street address that is associated with the student, such as their home address (STREET_ADDRESS),\n",
    "\n",
    "You will be given a text as Input, and your Response will be a list of each instance of Personally Identifiable Information and its type. Write each item in the list in the following format: data (PERSONAL INFORMATION TYPE).\n",
    "If data is not a personal information that fits the previously mentioned criteria, do not include it in the list.\n",
    "\n",
    "### Input:\n",
    "John Doe, I live in the 123 Main Street. My website is www.seanhalpin.xyz and my contact number is 888-688-5461.\n",
    "\n",
    "### Response:\n",
    "[/INST] John Doe (NAME_STUDENT),\n",
    "123 Main Street (STREET_ADDRESS),\n",
    "www.seanhalpin.xyz (URL_PERSONAL)\n",
    "830-688-0393 (PHONE_NUM)</s>\n",
    "<s>[INST] You are a helpful and honest assistant trained to identify and categorize Personally Identifiable Information in a given text. You are searching for these different types of Personally Identifiable Information:\n",
    "\n",
    "The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names (NAME_STUDENT),\n",
    "The email address of a student (EMAIL),\n",
    "The username of a student on any platform (USERNAME),\n",
    "A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number (ID_NUM),\n",
    "A phone number associated with a student (PHONE_NUM),\n",
    "A URL that might be used to identify a student (URL_PERSONAL),\n",
    "A full or partial street address that is associated with the student, such as their home address (STREET_ADDRESS),\n",
    "\n",
    "You will be given a text as Input, and your Response will be a list of each instance of Personally Identifiable Information and its type. Write each item in the list in the following format: data (PERSONAL INFORMATION TYPE).\n",
    "If data is not a personal information that fits the previously mentioned criteria, do not include it in the list.\n",
    "\n",
    "### Input:\n",
    "{text}\n",
    "\n",
    "### Response:\n",
    "[/INST] {answer}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "L-yo0_YQy3-a",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:21.982735Z",
     "start_time": "2024-04-23T16:25:21.361470500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  6807\n",
      "Test Data:  10\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"pii-detection-data/train.json\"\n",
    "test_data_path = \"pii-detection-data/test.json\"\n",
    "\n",
    "# Loading Dataset\n",
    "with open(train_data_path) as file:\n",
    "    train_data_json = json.load(file)\n",
    "    print(\"Training Data: \", len(train_data_json))\n",
    "\n",
    "with open(test_data_path ) as file:\n",
    "    test_data_json = json.load(file)\n",
    "    print(\"Test Data: \", len(test_data_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i8sVj8Lwy3-a",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:21.984738400Z",
     "start_time": "2024-04-23T16:25:21.983735900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size:  13\n"
     ]
    }
   ],
   "source": [
    "# Limiting the data for testing\n",
    "train_data_size = int(len(train_data_json) * 0.002)\n",
    "print(\"Train Data Size: \", train_data_size)\n",
    "\n",
    "train_data = train_data_json[:train_data_size]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_text = \" \".join(train_data[0][\"tokens\"][:400])\n",
    "format_prompt(input_text)"
   ],
   "metadata": {
    "id": "Y9P8u_NT1Aec",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:23.116186200Z",
     "start_time": "2024-04-23T16:25:23.108672700Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "\"<s>[INST] You are a helpful and honest assistant trained to identify and categorize Personally Identifiable Information in a given text. You are searching for these different types of Personally Identifiable Information:\\n\\nThe full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names (NAME_STUDENT),\\nThe email address of a student (EMAIL),\\nThe username of a student on any platform (USERNAME),\\nA number or sequence of characters that could be used to identify a student, such as a student ID or a social security number (ID_NUM),\\nA phone number associated with a student (PHONE_NUM),\\nA URL that might be used to identify a student (URL_PERSONAL),\\nA full or partial street address that is associated with the student, such as their home address (STREET_ADDRESS),\\n\\nYou will be given a text as Input, and your Response will be a list of each instance of Personally Identifiable Information and its type. Write each item in the list in the following format: data (PERSONAL INFORMATION TYPE).\\nIf data is not a personal information that fits the previously mentioned criteria, do not include it in the list.\\n\\n### Input:\\nJohn Doe, I live in the 123 Main Street. My website is www.seanhalpin.xyz and my contact number is 888-688-5461.\\n\\n### Response:\\n[/INST] John Doe (NAME_STUDENT),\\n123 Main Street (STREET_ADDRESS),\\nwww.seanhalpin.xyz (URL_PERSONAL)\\n830-688-0393 (PHONE_NUM)</s>\\n<s>[INST] You are a helpful and honest assistant trained to identify and categorize Personally Identifiable Information in a given text. You are searching for these different types of Personally Identifiable Information:\\n\\nThe full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names (NAME_STUDENT),\\nThe email address of a student (EMAIL),\\nThe username of a student on any platform (USERNAME),\\nA number or sequence of characters that could be used to identify a student, such as a student ID or a social security number (ID_NUM),\\nA phone number associated with a student (PHONE_NUM),\\nA URL that might be used to identify a student (URL_PERSONAL),\\nA full or partial street address that is associated with the student, such as their home address (STREET_ADDRESS),\\n\\nYou will be given a text as Input, and your Response will be a list of each instance of Personally Identifiable Information and its type. Write each item in the list in the following format: data (PERSONAL INFORMATION TYPE).\\nIf data is not a personal information that fits the previously mentioned criteria, do not include it in the list.\\n\\n### Input:\\nDesign Thinking for innovation reflexion - Avril 2021 - Nathalie Sylla \\n\\n Challenge & selection \\n\\n The tool I use to help all stakeholders finding their way through the complexity of a project is the   mind map . \\n\\n What exactly is a mind map ? According to the definition of Buzan T. and Buzan B. ( 1999 , Dessine - moi   l'intelligence . Paris : Les Éditions d'Organisation . ) , the mind map ( or heuristic diagram ) is a graphic   representation technique that follows the natural functioning of the mind and allows the brain 's   potential to be released . Cf Annex1 \\n\\n This tool has many advantages : \\n\\n •   It is accessible to all and does not require significant material investment and can be done   quickly \\n\\n •   It is scalable \\n\\n •   It allows categorization and linking of information \\n\\n •   It can be applied to any type of situation : notetaking , problem solving , analysis , creation of   new ideas \\n\\n •   It is suitable for all people and is easy to learn \\n\\n •   It is fun and encourages exchanges \\n\\n •   It makes visible the dimension of projects , opportunities , interconnections \\n\\n •   It synthesizes \\n\\n •   It makes the project understandable \\n\\n •   It allows you to explore ideas \\n\\n The creation of a mind map starts with an idea / problem located at its center . This starting point   generates ideas / work areas , incremented around this center in a radial structure , which in turn is   completed with as many branches as new ideas . \\n\\n This tool enables creativity and logic to be mobilized , it is a map of the thoughts . \\n\\n Creativity is enhanced because participants feel comfortable with the method . \\n\\n Application & Insight \\n\\n I start the process of the mind map creation with the stakeholders standing around a large board   ( white or paper board ) . In the center of the board , I write and highlight the topic to design . \\n\\n Through a series of questions , I guide the stakeholders in modelling the mind map . I adapt the series   of questions according to the topic to be addressed . In the type\\n\\n### Response:\\n[/INST] \""
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Setting Hyperparameters\n",
    "sampling_params = SamplingParams(temperature=0.001, max_tokens=150)"
   ],
   "metadata": {
    "id": "6rfQBrESR-D-",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:24.862296100Z",
     "start_time": "2024-04-23T16:25:24.852783100Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Input\n",
    "input_text = \" \".join(train_data[0][\"tokens\"][400:])\n",
    "input_text"
   ],
   "metadata": {
    "id": "TdGuEF5mMjfy",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:25:26.008523100Z",
     "start_time": "2024-04-23T16:25:25.999010600Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'of questions , we can use : who , what ,   when , where , why , how , how much . \\n\\n The use of the “ why ” is very interesting to understand the origin . By this way , the interviewed person   frees itself from paradigms and thus dares to propose new ideas / ways of functioning . I plan two   hours for a workshop . \\n\\n Design Thinking for innovation reflexion - Avril 2021 - Nathalie Sylla \\n\\n After modelling the mind map on paper , I propose to the participants a digital visualization of their   work with the addition of color codes , images and interconnections . This second workshop also lasts   two hours and allows the mind map to evolve . Once familiarized with it , the stakeholders discover   the power of the tool . Then , the second workshop brings out even more ideas and constructive   exchanges between the stakeholders . Around this new mind map , they have learned to work   together and want to make visible the untold ideas . \\n\\n I now present all the projects I manage in this type of format in order to ease rapid understanding for   decision - makers . These presentations are the core of my business models . The decision - makers are   thus able to identify the opportunities of the projects and can take quick decisions to validate them .   They find answers to their questions thank to a schematic representation . \\n\\n Approach \\n\\n What I find amazing with the facilitation of this type of workshop is the participants commitment for   the project . This tool helps to give meaning . The participants appropriate the story and want to keep   writing it . Then , they easily become actors or sponsors of the project . A trust relationship is built ,   thus facilitating the implementation of related actions . \\n\\n Design Thinking for innovation reflexion - Avril 2021 - Nathalie Sylla \\n\\n Annex 1 : Mind Map Shared facilities project \\n\\n'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Testing Model\n",
    "outputs = llm.generate(\n",
    "    [format_prompt(input_text)],\n",
    "    sampling_params\n",
    "    )\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print()\n",
    "    print(\"Generated text:\\n\", generated_text)"
   ],
   "metadata": {
    "id": "QRQ7jFHYztXv",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:26:01.987049500Z",
     "start_time": "2024-04-23T16:25:26.958208500Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:34<00:00, 34.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated text:\n",
      "  Here is the list of Personally Identifiable Information in the given text:\n",
      "\n",
      "* Nathalie Sylla (NAME_STUDENT)\n",
      "* Avril 2021 (DATE_PERSONAL)\n",
      "* 2 hours (DURATION_PERSONAL)\n",
      "* 2 hours (DURATION_PERSONAL)\n",
      "* 12:00 (TIME_PERSONAL)\n",
      "* 14:00 (TIME_PERSONAL)\n",
      "* 2021 (YEAR_PERSONAL)\n",
      "* April (MONTH_PERSONAL)\n",
      "* 2021 (YEAR_PERSONAL)\n",
      "* 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "outputs = re.split(r',?\\n', generated_text)\n",
    "print(outputs)\n",
    "outputs = [output.strip() for output in outputs if re.search(f\"\\S+\\s?\\(({pii_labels_pattern})\\)\", output)]\n",
    "print(\"List of PII:\\n\", outputs)"
   ],
   "metadata": {
    "id": "d4dZ55Lz61H6",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:26:16.034133800Z",
     "start_time": "2024-04-23T16:26:15.982539600Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Here is the list of Personally Identifiable Information in the given text:', '', '* Nathalie Sylla (NAME_STUDENT)', '* Avril 2021 (DATE_PERSONAL)', '* 2 hours (DURATION_PERSONAL)', '* 2 hours (DURATION_PERSONAL)', '* 12:00 (TIME_PERSONAL)', '* 14:00 (TIME_PERSONAL)', '* 2021 (YEAR_PERSONAL)', '* April (MONTH_PERSONAL)', '* 2021 (YEAR_PERSONAL)', '* 1']\n",
      "List of PII:\n",
      " ['* Nathalie Sylla (NAME_STUDENT)']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_text_input_ids = []\n",
    "train_labels_input_ids = []\n",
    "max_length = 400\n",
    "total_classifications = 0\n",
    "num_misclassified = 0\n",
    "num_hallucinated = 0\n",
    "\n",
    "try:\n",
    "    for i, data in enumerate(train_data):\n",
    "        print(\"Processing Sample:\", i)\n",
    "        # Loop through data in batches of 400 tokens\n",
    "        inputs, labels = get_batches(data)\n",
    "        print(\"Number of Text Splits:\", len(inputs))\n",
    "\n",
    "        model_outputs = llm.generate(\n",
    "            [format_prompt(input) for input in inputs],\n",
    "            sampling_params\n",
    "            )\n",
    "        print()\n",
    "\n",
    "        # Print the outputs.\n",
    "        for input_text, output_labels, model_output in zip(inputs, labels, model_outputs):\n",
    "            generated_text = model_output.outputs[0].text\n",
    "\n",
    "            # Process output text\n",
    "            outputs = re.split(r',?\\n', generated_text)\n",
    "            outputs = [output.strip() for output in outputs if re.search(f\"\\S+\\s?\\(({pii_labels_pattern})\\)\", output)]\n",
    "            print(\"List of PII:\\n\", outputs)\n",
    "\n",
    "            expected_labels = len(output_labels) - output_labels.count('O')\n",
    "            total_classifications += expected_labels\n",
    "\n",
    "            if(not outputs):\n",
    "                num_misclassified += expected_labels\n",
    "                print('Invalid Output:')\n",
    "                print(\"Input:\\n\", input_text)\n",
    "                print(\"Generated Text:\\n\", generated_text)\n",
    "                print(\"Labels:\\n\", output_labels)\n",
    "\n",
    "                continue\n",
    "\n",
    "            output_text = '\\n'.join(outputs)\n",
    "\n",
    "            # Assigning Labels\n",
    "            labeled_output = assign_labels(input_text, output_text)\n",
    "            curate_labels(labeled_output)\n",
    "\n",
    "            print(\"Input:\\n\", input_text)\n",
    "            print(\"Generated Text:\\n\", generated_text)\n",
    "            print(\"Labels:\\n\", output_labels)\n",
    "            print(\"Output:\\n\", labeled_output)\n",
    "\n",
    "            assert len(output_labels) == len(labeled_output)\n",
    "\n",
    "            # Comparing output with expected labels\n",
    "            for i in range(len(labeled_output)):\n",
    "                if(labeled_output[i] == output_labels[i]):\n",
    "                  continue\n",
    "\n",
    "                if(output_labels[i] == 'O'):\n",
    "                    num_hallucinated += 1\n",
    "                    num_misclassified += 1\n",
    "                    total_classifications += 1\n",
    "                else:\n",
    "                    num_misclassified += 1\n",
    "\n",
    "            print(\"Number Hallucinated:\", num_hallucinated)\n",
    "            print(\"Total Missclassified:\", num_misclassified)\n",
    "\n",
    "        print()\n",
    "        print(\"Misclassification:\", num_misclassified / total_classifications)\n",
    "        print(\"Accuracy:\", (total_classifications - num_misclassified) / total_classifications)\n",
    "        print(\"Accuracy Excluding Hallucinations:\", (total_classifications - num_misclassified) / (total_classifications - num_hallucinated))\n",
    "        print()\n",
    "\n",
    "except Exception as error:\n",
    "    print(\"\\nError Occured for the following input:\")\n",
    "    print(\"INPUT:\", input_text)\n",
    "    print(\"EXPECTED OUTPUT:\", output_labels)\n",
    "    print(\"GENERATED TEXT:\", generated_text)\n",
    "    print(\"PROCESSED OUTPUT:\", outputs)\n",
    "    print(\"LABELED OUTPUT:\", labeled_output)\n",
    "    print('Output Labels:',len(output_labels),'Labeled Output:', len(labeled_output))\n",
    "    print(\"ERROR:\", error)\n"
   ],
   "metadata": {
    "id": "U7Uz3DoD-el2",
    "ExecuteTime": {
     "end_time": "2024-04-23T16:29:09.551272500Z",
     "start_time": "2024-04-23T16:26:18.917549500Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Sample: 0\n",
      "Number of Text Splits: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 2/2 [01:11<00:00, 35.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of PII:\n",
      " ['* Nathalie Sylla (NAME_STUDENT)', '* Annex1 (URL_PERSONAL)']\n",
      "Input:\n",
      " Design Thinking for innovation reflexion - Avril 2021 - Nathalie Sylla \n",
      "\n",
      " Challenge & selection \n",
      "\n",
      " The tool I use to help all stakeholders finding their way through the complexity of a project is the   mind map . \n",
      "\n",
      " What exactly is a mind map ? According to the definition of Buzan T. and Buzan B. ( 1999 , Dessine - moi   l'intelligence . Paris : Les Éditions d'Organisation . ) , the mind map ( or heuristic diagram ) is a graphic   representation technique that follows the natural functioning of the mind and allows the brain 's   potential to be released . Cf Annex1 \n",
      "\n",
      " This tool has many advantages : \n",
      "\n",
      " •   It is accessible to all and does not require significant material investment and can be done   quickly \n",
      "\n",
      " •   It is scalable \n",
      "\n",
      " •   It allows categorization and linking of information \n",
      "\n",
      " •   It can be applied to any type of situation : notetaking , problem solving , analysis , creation of   new ideas \n",
      "\n",
      " •   It is suitable for all people and is easy to learn \n",
      "\n",
      " •   It is fun and encourages exchanges \n",
      "\n",
      " •   It makes visible the dimension of projects , opportunities , interconnections \n",
      "\n",
      " •   It synthesizes \n",
      "\n",
      " •   It makes the project understandable \n",
      "\n",
      " •   It allows you to explore ideas \n",
      "\n",
      " The creation of a mind map starts with an idea / problem located at its center . This starting point   generates ideas / work areas , incremented around this center in a radial structure , which in turn is   completed with as many branches as new ideas . \n",
      "\n",
      " This tool enables creativity and logic to be mobilized , it is a map of the thoughts . \n",
      "\n",
      " Creativity is enhanced because participants feel comfortable with the method . \n",
      "\n",
      " Application & Insight \n",
      "\n",
      " I start the process of the mind map creation with the stakeholders standing around a large board   ( white or paper board ) . In the center of the board , I write and highlight the topic to design . \n",
      "\n",
      " Through a series of questions , I guide the stakeholders in modelling the mind map . I adapt the series   of questions according to the topic to be addressed . In the type\n",
      "Generated Text:\n",
      "  Here is the list of Personally Identifiable Information in the given text:\n",
      "\n",
      "* Nathalie Sylla (NAME_STUDENT)\n",
      "* Avril 2021 (PERSONAL INFORMATION)\n",
      "* Buzan T. (PERSONAL INFORMATION)\n",
      "* Buzan B. (PERSONAL INFORMATION)\n",
      "* Annex1 (URL_PERSONAL)\n",
      "* 1999 (PERSONAL INFORMATION)\n",
      "Labels:\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Output:\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Number Hallucinated: 0\n",
      "Total Missclassified: 2\n",
      "List of PII:\n",
      " ['* Nathalie Sylla (NAME_STUDENT)']\n",
      "Input:\n",
      " of questions , we can use : who , what ,   when , where , why , how , how much . \n",
      "\n",
      " The use of the “ why ” is very interesting to understand the origin . By this way , the interviewed person   frees itself from paradigms and thus dares to propose new ideas / ways of functioning . I plan two   hours for a workshop . \n",
      "\n",
      " Design Thinking for innovation reflexion - Avril 2021 - Nathalie Sylla \n",
      "\n",
      " After modelling the mind map on paper , I propose to the participants a digital visualization of their   work with the addition of color codes , images and interconnections . This second workshop also lasts   two hours and allows the mind map to evolve . Once familiarized with it , the stakeholders discover   the power of the tool . Then , the second workshop brings out even more ideas and constructive   exchanges between the stakeholders . Around this new mind map , they have learned to work   together and want to make visible the untold ideas . \n",
      "\n",
      " I now present all the projects I manage in this type of format in order to ease rapid understanding for   decision - makers . These presentations are the core of my business models . The decision - makers are   thus able to identify the opportunities of the projects and can take quick decisions to validate them .   They find answers to their questions thank to a schematic representation . \n",
      "\n",
      " Approach \n",
      "\n",
      " What I find amazing with the facilitation of this type of workshop is the participants commitment for   the project . This tool helps to give meaning . The participants appropriate the story and want to keep   writing it . Then , they easily become actors or sponsors of the project . A trust relationship is built ,   thus facilitating the implementation of related actions . \n",
      "\n",
      " Design Thinking for innovation reflexion - Avril 2021 - Nathalie Sylla \n",
      "\n",
      " Annex 1 : Mind Map Shared facilities project \n",
      "\n",
      "\n",
      "Generated Text:\n",
      "  Here is the list of Personally Identifiable Information in the given text:\n",
      "\n",
      "* Nathalie Sylla (NAME_STUDENT)\n",
      "* Avril 2021 (DATE_PERSONAL)\n",
      "* 2 hours (DURATION_PERSONAL)\n",
      "* 2 hours (DURATION_PERSONAL)\n",
      "* 12:00 (TIME_PERSONAL)\n",
      "* 14:00 (TIME_PERSONAL)\n",
      "* 2021 (YEAR_PERSONAL)\n",
      "* April (MONTH_PERSONAL)\n",
      "* 2021 (YEAR_PERSONAL)\n",
      "* 1\n",
      "Labels:\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Output:\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Number Hallucinated: 0\n",
      "Total Missclassified: 6\n",
      "\n",
      "Misclassification: 1.0\n",
      "Accuracy: 0.0\n",
      "Accuracy Excluding Hallucinations: 0.0\n",
      "\n",
      "Processing Sample: 1\n",
      "Number of Text Splits: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 2/2 [00:54<00:00, 27.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of PII:\n",
      " ['Diego Estrada (NAME_STUDENT)', 'Visualization Tool (URL_PERSONAL)', '888-688-5461 (PHONE_NUM)', 'Diego.Estrada@gmail.com (EMAIL)', 'The full or partial street address that is associated with the student, such as their home address (STREET_ADDRESS)', 'The full or partial name of a student that is not necessarily the author of the essay (NAME_STUDENT)', 'The email address of a student (EMAIL)']\n",
      "Input:\n",
      " Diego Estrada \n",
      "\n",
      " Design Thinking Assignment \n",
      "\n",
      " Visualization Tool \n",
      "\n",
      " Challenge & Selection \n",
      "\n",
      " The elderly were having a hard time adapting to the changes we brought in our bank . As   a result of a poorly implemented linear solution , a more customer centric approach was   needed . \n",
      "\n",
      " After learning about design thinking in this course , we decided to apply it to solve this   problem . The visualization tool allowed the team to create a dynamic presentation using   diagrams , figures and drawings on the go that really resonated among the stakeholders .   Previous to this change , none of our solutions seemed to be adequate for them , but the   new implementation created a different type of connection with them that helped them   understand the problem in the way the team and I did . \n",
      "\n",
      " Application \n",
      "\n",
      " The process starts in the prep time . The team uses a series of tools and software to   develop a presentation using the surveys gathered during research and the solutions we   created during the process . The use of graphs to quickly show statistics in a fully visual   way , rather than verbally was a game changer . \n",
      "\n",
      " After having a presentation prepared , the team hands an activity to the stakeholders ,   where the solutions discussed previously appear . Nonetheless , the solutions need more   work to them . After this . The stakeholders are asked to help complete the solutions   while the team and I create diagrams on a blackboard to represent how their   suggestions would impact on this specific problem . \n",
      "\n",
      " The use of a group activity strengthens the bond between the company and their   investors . It makes them feel like they take part and help solve the problems as well as   show how customer centric the solutions are . Every complaint and suggestion from   customers are read and evaluated using the graph shown in the course ( Involving : can   we do it ? Can we afford it ? … ) . The finalization of this activity leaves the team and the   stakeholders on the same page . It allows them to completely understand and feel part   of the solution and also gives them the chance to ask better questions ,\n",
      "Generated Text:\n",
      "  Diego Estrada (NAME_STUDENT)\n",
      "Visualization Tool (URL_PERSONAL)\n",
      "888-688-5461 (PHONE_NUM)\n",
      "Diego.Estrada@gmail.com (EMAIL)\n",
      "\n",
      "### Response:\n",
      "\n",
      "The full or partial street address that is associated with the student, such as their home address (STREET_ADDRESS),\n",
      "\n",
      "### Response:\n",
      "\n",
      "The full or partial name of a student that is not necessarily the author of the essay (NAME_STUDENT),\n",
      "\n",
      "### Response:\n",
      "\n",
      "The email address of a student (EMAIL),\n",
      "\n",
      "### Response:\n",
      "\n",
      "The\n",
      "Labels:\n",
      " ['B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Output:\n",
      " ['B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'B-URL_PERSONAL', 'I-URL_PERSONAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Number Hallucinated: 2\n",
      "Total Missclassified: 8\n",
      "List of PII:\n",
      " ['Diego Estrada (NAME_STUDENT)', '123 Main Street (STREET_ADDRESS)']\n",
      "Input:\n",
      " which eases the   work of the team . \n",
      "\n",
      " Insight & Approach \n",
      "\n",
      " The use of this method created a new workflow in the Design Team . It increased the   productivity and the success rate as well as the customer / stakeholders satisfaction . The   use of the visualization tool created an engaged group of people who work together to \n",
      "\n",
      " Diego Estrada \n",
      "\n",
      " find a solution based on their customer satisfaction . This solution is later revised and   tweaked with the help of the stakeholders who are deeply involved in the process . \n",
      "\n",
      " Presentations , graphics , and activities have added a huge increase in satisfaction . As a   company we also learnt that engaging different areas can be difficult because of the   varying levels of understanding , but when paired with the adequate process things just   flow . \n",
      "\n",
      " ( This story is fictional and was created for solving the assignment ) \n",
      "\n",
      "\n",
      "Generated Text:\n",
      "  Diego Estrada (NAME_STUDENT)\n",
      "123 Main Street (STREET_ADDRESS)\n",
      "(EMAIL)\n",
      "(USERNAME)\n",
      "(ID_NUM)\n",
      "(PHONE_NUM)\n",
      "(URL_PERSONAL)\n",
      "\n",
      "Labels:\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Output:\n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Number Hallucinated: 2\n",
      "Total Missclassified: 8\n",
      "\n",
      "Misclassification: 0.6666666666666666\n",
      "Accuracy: 0.3333333333333333\n",
      "Accuracy Excluding Hallucinations: 0.4\n",
      "\n",
      "Processing Sample: 2\n",
      "Number of Text Splits: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:  50%|█████     | 1/2 [00:32<00:32, 32.79s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m get_batches(data)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of Text Splits:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(inputs))\n\u001B[0;32m---> 15\u001B[0m model_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mformat_prompt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43msampling_params\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m()\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Print the outputs.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/entrypoints/llm.py:190\u001B[0m, in \u001B[0;36mLLM.generate\u001B[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, multi_modal_data)\u001B[0m\n\u001B[1;32m    177\u001B[0m     token_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m prompt_token_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m prompt_token_ids[\n\u001B[1;32m    178\u001B[0m         i]\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_request(\n\u001B[1;32m    180\u001B[0m         prompt,\n\u001B[1;32m    181\u001B[0m         sampling_params,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    188\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m multi_modal_data \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    189\u001B[0m     )\n\u001B[0;32m--> 190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43muse_tqdm\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/entrypoints/llm.py:218\u001B[0m, in \u001B[0;36mLLM._run_engine\u001B[0;34m(self, use_tqdm)\u001B[0m\n\u001B[1;32m    216\u001B[0m outputs: List[RequestOutput] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_engine\u001B[38;5;241m.\u001B[39mhas_unfinished_requests():\n\u001B[0;32m--> 218\u001B[0m     step_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m step_outputs:\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m output\u001B[38;5;241m.\u001B[39mfinished:\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/engine/llm_engine.py:676\u001B[0m, in \u001B[0;36mLLMEngine.step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m seq_group_metadata_list, scheduler_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mschedule()\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m scheduler_outputs\u001B[38;5;241m.\u001B[39mis_empty():\n\u001B[0;32m--> 676\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseq_group_metadata_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler_outputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks_to_swap_in\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscheduler_outputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks_to_swap_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscheduler_outputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks_to_copy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    681\u001B[0m     output \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:114\u001B[0m, in \u001B[0;36mGPUExecutor.execute_model\u001B[0;34m(self, seq_group_metadata_list, blocks_to_swap_in, blocks_to_swap_out, blocks_to_copy)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute_model\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    110\u001B[0m                   seq_group_metadata_list: List[SequenceGroupMetadata],\n\u001B[1;32m    111\u001B[0m                   blocks_to_swap_in: Dict[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m],\n\u001B[1;32m    112\u001B[0m                   blocks_to_swap_out: Dict[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m],\n\u001B[1;32m    113\u001B[0m                   blocks_to_copy: Dict[\u001B[38;5;28mint\u001B[39m, List[\u001B[38;5;28mint\u001B[39m]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SamplerOutput:\n\u001B[0;32m--> 114\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdriver_worker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    115\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseq_group_metadata_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseq_group_metadata_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mblocks_to_swap_in\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblocks_to_swap_in\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mblocks_to_swap_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblocks_to_swap_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mblocks_to_copy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblocks_to_copy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/worker/worker.py:221\u001B[0m, in \u001B[0;36mWorker.execute_model\u001B[0;34m(self, seq_group_metadata_list, blocks_to_swap_in, blocks_to_swap_out, blocks_to_copy)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_seq_groups \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {}\n\u001B[0;32m--> 221\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseq_group_metadata_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m                                         \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgpu_cache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/worker/model_runner.py:673\u001B[0m, in \u001B[0;36mModelRunner.execute_model\u001B[0;34m(self, seq_group_metadata_list, kv_caches)\u001B[0m\n\u001B[1;32m    670\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;66;03m# Sample the next token.\u001B[39;00m\n\u001B[0;32m--> 673\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[43msampling_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msampling_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/model_executor/models/llama.py:360\u001B[0m, in \u001B[0;36mLlamaForCausalLM.sample\u001B[0;34m(self, logits, sampling_metadata)\u001B[0m\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msample\u001B[39m(\n\u001B[1;32m    356\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    357\u001B[0m     logits: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m    358\u001B[0m     sampling_metadata: SamplingMetadata,\n\u001B[1;32m    359\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[SamplerOutput]:\n\u001B[0;32m--> 360\u001B[0m     next_tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    361\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m next_tokens\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/model_executor/layers/sampler.py:76\u001B[0m, in \u001B[0;36mSampler.forward\u001B[0;34m(self, logits, sampling_metadata)\u001B[0m\n\u001B[1;32m     73\u001B[0m logprobs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlog_softmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# Sample the next tokens.\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m sample_results \u001B[38;5;241m=\u001B[39m \u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m                         \u001B[49m\u001B[43msampling_tensors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# Get the logprobs query results.\u001B[39;00m\n\u001B[1;32m     79\u001B[0m prompt_logprobs, sample_logprobs \u001B[38;5;241m=\u001B[39m _get_logprobs(\n\u001B[1;32m     80\u001B[0m     logprobs, sampling_metadata, sample_results)\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/model_executor/layers/sampler.py:502\u001B[0m, in \u001B[0;36m_sample\u001B[0;34m(probs, logprobs, sampling_metadata, sampling_tensors)\u001B[0m\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sample\u001B[39m(\n\u001B[1;32m    497\u001B[0m     probs: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m    498\u001B[0m     logprobs: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m    499\u001B[0m     sampling_metadata: SamplingMetadata,\n\u001B[1;32m    500\u001B[0m     sampling_tensors: SamplingTensors,\n\u001B[1;32m    501\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Tuple[List[\u001B[38;5;28mint\u001B[39m], List[\u001B[38;5;28mint\u001B[39m]]]:\n\u001B[0;32m--> 502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_sample_with_torch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/model_executor/layers/sampler.py:401\u001B[0m, in \u001B[0;36m_sample_with_torch\u001B[0;34m(probs, logprobs, sampling_metadata)\u001B[0m\n\u001B[1;32m    399\u001B[0m     sample_results \u001B[38;5;241m=\u001B[39m _greedy_sample(seq_groups, greedy_samples)\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m sampling_type \u001B[38;5;129;01min\u001B[39;00m (SamplingType\u001B[38;5;241m.\u001B[39mRANDOM, SamplingType\u001B[38;5;241m.\u001B[39mRANDOM_SEED):\n\u001B[0;32m--> 401\u001B[0m     sample_results \u001B[38;5;241m=\u001B[39m \u001B[43m_random_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseq_groups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_prompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mmultinomial_samples\u001B[49m\u001B[43m[\u001B[49m\u001B[43msampling_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m sampling_type \u001B[38;5;241m==\u001B[39m SamplingType\u001B[38;5;241m.\u001B[39mBEAM:\n\u001B[1;32m    404\u001B[0m     sample_results \u001B[38;5;241m=\u001B[39m _beam_search_sample(seq_groups, is_prompts,\n\u001B[1;32m    405\u001B[0m                                          sampling_metadata\u001B[38;5;241m.\u001B[39mseq_data,\n\u001B[1;32m    406\u001B[0m                                          beam_search_logprobs)\n",
      "File \u001B[0;32m~/miniconda3/envs/PII/lib/python3.10/site-packages/vllm/model_executor/layers/sampler.py:235\u001B[0m, in \u001B[0;36m_random_sample\u001B[0;34m(selected_seq_groups, is_prompts, random_samples)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_random_sample\u001B[39m(\n\u001B[1;32m    230\u001B[0m     selected_seq_groups: List[Tuple[List[\u001B[38;5;28mint\u001B[39m], SamplingParams]],\n\u001B[1;32m    231\u001B[0m     is_prompts: List[\u001B[38;5;28mbool\u001B[39m],\n\u001B[1;32m    232\u001B[0m     random_samples: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m    233\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Tuple[List[\u001B[38;5;28mint\u001B[39m], List[\u001B[38;5;28mint\u001B[39m]]]:\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;66;03m# Find the maximum best_of value of the prompt phase requests.\u001B[39;00m\n\u001B[0;32m--> 235\u001B[0m     random_samples \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_samples\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m     sample_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    237\u001B[0m     results \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
