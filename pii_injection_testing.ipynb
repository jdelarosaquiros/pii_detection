{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers ipywidgets vllm nltk datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_full_repo_name' from 'huggingface_hub' (/root/miniconda3/envs/pii/lib/python3.10/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM, SamplingParams\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"vLLM: a high-throughput and memory-efficient inference engine for LLMs\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marg_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncEngineArgs, EngineArgs\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_llm_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncLLMEngine\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMEngine\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/engine/arg_utils.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Tuple, Union\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (CacheConfig, DecodingConfig, DeviceConfig,\n\u001b[1;32m      8\u001b[0m                          EngineConfig, LoadConfig, LoRAConfig, ModelConfig,\n\u001b[1;32m      9\u001b[0m                          ParallelConfig, SchedulerConfig, SpeculativeConfig,\n\u001b[1;32m     10\u001b[0m                          TokenizerPoolConfig, VisionLanguageConfig)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QUANTIZATION_METHODS\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m str_to_int_tuple\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/config.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, ClassVar, List, Optional, Tuple, Union\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_executor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QUANTIZATION_METHODS\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     logging,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/transformers/utils/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_full_repo_name  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HF_HUB_DISABLE_TELEMETRY \u001b[38;5;28;01mas\u001b[39;00m DISABLE_TELEMETRY  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_full_repo_name' from 'huggingface_hub' (/root/miniconda3/envs/pii/lib/python3.10/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "import random\n",
    "import json\n",
    "import nltk\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from generate_pii_dataset import generate_pii_dataset\n",
    "from utils.pii_injection_utils import (\n",
    "    get_pii_list,\n",
    "    generate_data_transition,\n",
    "    generate_text_transition,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e782c9a7f34b52af6d810001ebf680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Login to huggingface\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-01 19:59:43 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='meta-llama/Meta-Llama-3-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=meta-llama/Meta-Llama-3-8B-Instruct)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pii/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-01 19:59:43 utils.py:660] Found nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "WARNING 06-01 19:59:43 utils.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the model and tokenizer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/entrypoints/llm.py:123\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, enforce_eager, max_context_len_to_capture, max_seq_len_to_capture, disable_custom_all_reduce, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    103\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    104\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    105\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    122\u001b[0m )\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/engine/llm_engine.py:292\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context)\u001b[0m\n\u001b[1;32m    289\u001b[0m     executor_class \u001b[38;5;241m=\u001b[39m GPUExecutor\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/engine/llm_engine.py:160\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, vision_language_config, speculative_config, decoding_config, executor_class, log_stats, usage_context)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_counter \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config_fields \u001b[38;5;241m=\u001b[39m _load_generation_config_dict(\n\u001b[1;32m    158\u001b[0m     model_config)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvision_language_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeculative_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeculative_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_kv_caches()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If usage stat is enabled, collect relevant info.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/executor/executor_base.py:41\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, vision_language_config, speculative_config)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_language_config \u001b[38;5;241m=\u001b[39m vision_language_config\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeculative_config \u001b[38;5;241m=\u001b[39m speculative_config\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:23\u001b[0m, in \u001b[0;36mGPUExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the worker and load the model.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mIf speculative decoding is enabled, we instead create the speculative\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mworker.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeculative_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_non_spec_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_spec_worker()\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:67\u001b[0m, in \u001b[0;36mGPUExecutor._init_non_spec_worker\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_non_spec_worker\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPUExecutor only supports single GPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker\u001b[38;5;241m.\u001b[39minit_device()\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker\u001b[38;5;241m.\u001b[39mload_model()\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:59\u001b[0m, in \u001b[0;36mGPUExecutor._create_worker\u001b[0;34m(self, local_rank, rank, distributed_init_method)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_worker\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m                    local_rank: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     53\u001b[0m                    rank: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     54\u001b[0m                    distributed_init_method: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m     wrapper \u001b[38;5;241m=\u001b[39m WorkerWrapperBase(\n\u001b[1;32m     56\u001b[0m         worker_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvllm.worker.worker\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m         worker_class_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorker\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m     )\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_worker_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mdistributed_init_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\u001b[38;5;241m.\u001b[39mworker\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/worker/worker_base.py:131\u001b[0m, in \u001b[0;36mWorkerWrapperBase.init_worker\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m mod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_module_name)\n\u001b[1;32m    130\u001b[0m worker_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_class_name)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker \u001b[38;5;241m=\u001b[39m \u001b[43mworker_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/worker/worker.py:73\u001b[0m, in \u001b[0;36mWorker.__init__\u001b[0;34m(self, model_config, parallel_config, scheduler_config, device_config, cache_config, load_config, local_rank, rank, distributed_init_method, lora_config, vision_language_config, is_driver_worker)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_language_config:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_config, (\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo be tested: vision language model with LoRA settings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_runner \u001b[38;5;241m=\u001b[39m \u001b[43mModelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_cache_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_driver_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_driver_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvision_language_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Uninitialized cache engine. Will be initialized by\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# initialize_cache.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_engine: CacheEngine\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/worker/model_runner.py:145\u001b[0m, in \u001b[0;36mModelRunner.__init__\u001b[0;34m(self, model_config, parallel_config, scheduler_config, device_config, load_config, lora_config, kv_cache_dtype, is_driver_worker, vision_language_config)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkv_cache_dtype \u001b[38;5;241m=\u001b[39m kv_cache_dtype\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_language_config \u001b[38;5;241m=\u001b[39m vision_language_config\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_backend \u001b[38;5;241m=\u001b[39m \u001b[43mget_attn_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Lazy initialization\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule  \u001b[38;5;66;03m# Set after load_model\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/attention/selector.py:25\u001b[0m, in \u001b[0;36mget_attn_backend\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_attn_backend\u001b[39m(dtype: torch\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Type[AttentionBackend]:\n\u001b[0;32m---> 25\u001b[0m     backend \u001b[38;5;241m=\u001b[39m \u001b[43m_which_attn_to_use\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m _Backend\u001b[38;5;241m.\u001b[39mFLASH_ATTN:\n\u001b[1;32m     27\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing FlashAttention-2 backend.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/vllm/attention/selector.py:67\u001b[0m, in \u001b[0;36m_which_attn_to_use\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _Backend\u001b[38;5;241m.\u001b[39mROCM_FLASH\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# NVIDIA GPUs.\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_capability\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m8\u001b[39m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Volta and Turing NVIDIA GPUs.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use FlashAttention-2 backend for Volta and Turing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPUs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _Backend\u001b[38;5;241m.\u001b[39mXFORMERS\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/torch/cuda/__init__.py:430\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_capability\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m        tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     prop \u001b[38;5;241m=\u001b[39m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prop\u001b[38;5;241m.\u001b[39mmajor, prop\u001b[38;5;241m.\u001b[39mminor\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/torch/cuda/__init__.py:444\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/miniconda3/envs/pii/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\" \n",
    "\n",
    "model = LLM(model=model_id, gpu_memory_utilization=0.9, tensor_parallel_size=1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': [],\n",
       " 'email': ['ilpisug@zot.ci',\n",
       "  'WAYNEvagjuv@ize.sl',\n",
       "  'SKINNY@bibdivo.su',\n",
       "  'Holt@ginsaufo.es',\n",
       "  'Elvapattersonsahavi@ho.re'],\n",
       " 'username': [],\n",
       " 'id_number': ['6919978449503183',\n",
       "  '019847530123598764',\n",
       "  '13789',\n",
       "  '78-47--2-2-5--32-96--5052836',\n",
       "  '4797_4_350'],\n",
       " 'phone_number': ['02 (320 537) 8935203', ' (823) 276 3 1564'],\n",
       " 'street_address': [],\n",
       " 'url': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate or load PII samples\n",
    "with open('grouped_pii_samples.json', 'r') as f:\n",
    "    grouped_pii_samples = json.load(f)\n",
    "\n",
    "grouped_pii_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['TEXT', 'SOURCE', '__index_level_0__'],\n",
       "        num_rows: 128293\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load source texts\n",
    "essay_dataset = load_dataset(\"qwedsacf/ivypanda-essays\")\n",
    "essay_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PII Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': [],\n",
       " 'email': ['ilpisug@zot.ci',\n",
       "  'WAYNEvagjuv@ize.sl',\n",
       "  'SKINNY@bibdivo.su',\n",
       "  'Holt@ginsaufo.es',\n",
       "  'Elvapattersonsahavi@ho.re'],\n",
       " 'username': [],\n",
       " 'id_number': ['6919978449503183',\n",
       "  '019847530123598764',\n",
       "  '13789',\n",
       "  '78-47--2-2-5--32-96--5052836',\n",
       "  '4797_4_350'],\n",
       " 'phone_number': ['02 (320 537) 8935203', ' (823) 276 3 1564'],\n",
       " 'street_address': [],\n",
       " 'url': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set pii sample\n",
    "pii_sample = grouped_pii_samples[0]\n",
    "pii_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Years a Slave: An Analysis of the Film Essay\n",
      "\n",
      "The 2013 film 12 Years a Slave proved that slavery is a worldwide issue. Indeed, the film made $150 million outside the United States and $57 million in the U.S., with a production budget of $20 million (Sharf, 2020). The movie was based on the memoir Twelve Years a Slave by Solomon Northup (Ntim, 2020). It tells the story of a free African American man who was kidnapped and sold into slavery. Solomon spent twelve years away from his family, being traded from one master to another. Fortunately, the protagonist met a person who helped him deliver a message to his family and friends, who came and rescued him. This movie accurately illustrates discriminatory relationships between white slaveholders and black slaves that stemmed from the dysfunctional system in the country and prejudices in people’s mindsets at that time.\n",
      "\n",
      "The two main ethnic groups presented in this film are White and African Americans, and the three social groups are affluent slaveholders, working for middle class, and enslaved people. The movie starts with the story of a free African American violinist Solomon Northup, living with his family in Saratoga, New York (McQueen, 2013). However, he was abducted by two white men, who tortured the man and sold him into slavery, changing his name to Plat. Before they met, Solomon and these two slave traders belonged to the same middle class. However, the fact that Northup was an African American made these individuals believe that they had the right to withdraw their freedom. The two masters that Solomon had were William Ford and Edwin Epps (McQueen, 2013). The former was kind and religious, while the latter was cruel and sadistic. Since the movie was based on a real story, it indicated that slaveholders had different characters, but all had the wrong perception of race.\n",
      "\n",
      "Although 12 Years a Slave is a film about slavery, the issues of collectivism and individualism are also raised. Specifically, the main character never identified himself as an enslaved man and continued claiming he was a free citizen (McQueen, 2013). However, his counterparts on the plant had a collective mindset, imprinted in them since childhood, that slavery is normal. These people helped each other because they belonged to the same group. Although Solomon tried to become a part of this community, his individual goal to return home was above the collective values.\n",
      "\n",
      "The movie also showed prejudice, generalizations, stereotyping, and discrimination against black people. For instance, when Ford brings Solomon and Elisa to his plantation, his wife expresses her sadness that Elisa got separated from her children. However, she also stated that “something to eat and some rest” could help that woman forget her children (McQueen, 2013, 32:47-32:51). This scene demonstrated the common prejudice about slaves that they were not capable of the same feelings as white people. An example of generalization and stereotyping was how Tibeats, a carpenter, became hostile to Solomon when he showed his intelligence and gave Ford advice. In fact, Tibeats believed that Plat would never be more competent than any white individual because Plat was a “nigger” (McQueen, 2013, 36:35-36:37). Notably, before Northup became enslaved, he never experienced discrimination, but when the main character was sold into slavery, discrimination was the only attitude that he could observe.\n",
      "\n",
      "In summary, 12 Years a Slave depicts the life of enslaved people and slave owners almost two centuries ago. The film narrates a free black man’s life from the moment when he enjoyed his family’s company in the state of New York to his abduction, enslavement, and eventual liberation. Overall, the movie raised such critical issues as discrimination, prejudice, stereotyping, and generalization that allowed slaveholders to maintain this societal structure for a long time.\n",
      "\n",
      "References\n",
      "\n",
      "McQueen, S. (2013). 12 years a slave [Film]. New Regency Productions.\n",
      "\n",
      "Ntim, Z. (2020). Steve McQueen says it took 11 years to create his new anthology “Small Axe” and reveals why producers almost pulled out of his Oscar-winning film “12 Years a Slave.” Insider.\n",
      "\n",
      "Sharf, Z. (2020). Steve McQueen recalls producers rejecting “12 Years a Slave” over false beliefs about black films. Indie Wire.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set text to be injected with PII\n",
    "text = essay_dataset['train'][0]['TEXT']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function inserts PII into the text\n",
    "def generate_pii_text(model, tokenizer, sampling_params, text, pii_map, split_by_sentence=True):\n",
    "    splitted_text = nltk.sent_tokenize(text) if split_by_sentence else text.split(' ')\n",
    "    pii_list = get_pii_list(pii_map)\n",
    "    print(pii_list)\n",
    "\n",
    "    for (pii, label) in pii_list:\n",
    "        pii_insert_index = random.randint(0, len(splitted_text))\n",
    "        first_text = ' '.join(splitted_text[:pii_insert_index])\n",
    "        second_text = ' '.join(splitted_text[pii_insert_index:])\n",
    "\n",
    "        transition = generate_data_transition(model, tokenizer, sampling_params, first_text, data=pii, data_type=label)\n",
    "        transition_before = transition\n",
    "        first_text = f\"{first_text} {transition_before} {pii}\"\n",
    "\n",
    "        transition = generate_text_transition(model, tokenizer, sampling_params, first_text=first_text, second_text=second_text)\n",
    "        transition_after = transition\n",
    "\n",
    "        splitted_text.insert(pii_insert_index, f\"{transition_before} {pii} {transition_after}\")\n",
    "    \n",
    "    pii_text = ' '.join(splitted_text)\n",
    "\n",
    "    return pii_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elvapattersonsahavi@ho.re', 'email'), ('78-47--2-2-5--32-96--5052836', 'id_number'), ('SKINNY@bibdivo.su', 'email'), (' (823) 276 3 1564', 'phone_number'), ('ilpisug@zot.ci', 'email'), ('6919978449503183', 'id_number'), ('13789', 'id_number'), ('WAYNEvagjuv@ize.sl', 'email'), ('Holt@ginsaufo.es', 'email'), ('02 (320 537) 8935203', 'phone_number'), ('019847530123598764', 'id_number'), ('4797_4_350', 'id_number')]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "generate_data_transition() got multiple values for argument 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m terminators \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39meos_token]\n\u001b[1;32m      3\u001b[0m sampling_params \u001b[38;5;241m=\u001b[39m SamplingParams(\n\u001b[1;32m      4\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, \n\u001b[1;32m      5\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     stop\u001b[38;5;241m=\u001b[39mterminators\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_pii_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpii_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_by_sentence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m, in \u001b[0;36mgenerate_pii_text\u001b[0;34m(model, tokenizer, sampling_params, text, pii_map, split_by_sentence)\u001b[0m\n\u001b[1;32m      9\u001b[0m first_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(splitted_text[:pii_insert_index])\n\u001b[1;32m     10\u001b[0m second_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(splitted_text[pii_insert_index:])\n\u001b[0;32m---> 12\u001b[0m transition \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_data_transition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m transition_before \u001b[38;5;241m=\u001b[39m transition\n\u001b[1;32m     14\u001b[0m first_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransition_before\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpii\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: generate_data_transition() got multiple values for argument 'data'"
     ]
    }
   ],
   "source": [
    "terminators = [tokenizer.eos_token]\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, \n",
    "    top_p=0.9, \n",
    "    max_tokens=2058, \n",
    "    skip_special_tokens=True,\n",
    "    stop=terminators\n",
    ")\n",
    "\n",
    "\n",
    "print(generate_pii_text(model, tokenizer, sampling_params, text, pii_sample, split_by_sentence=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:18<00:00,  1.84s/it]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.40it/s]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:19<00:00,  1.91s/it]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:04<00:00,  2.27it/s]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:29<00:00,  2.95s/it]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:16<00:00,  1.65s/it]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:32<00:00,  3.27s/it]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:26<00:00,  2.64s/it]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n",
      "Processed prompts: 100%|██████████| 10/10 [00:25<00:00,  2.54s/it]\n",
      "Processed prompts: 100%|██████████| 9/9 [00:08<00:00,  1.08it/s]\n",
      "Processed prompts: 100%|██████████| 9/9 [00:27<00:00,  3.10s/it]\n",
      "Processed prompts: 100%|██████████| 9/9 [00:21<00:00,  2.42s/it]\n",
      "Processed prompts: 100%|██████████| 9/9 [00:49<00:00,  5.53s/it]\n",
      "Processed prompts: 100%|██████████| 5/5 [00:06<00:00,  1.24s/it]\n",
      "Processed prompts: 100%|██████████| 5/5 [00:27<00:00,  5.46s/it]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:04<00:00,  1.08s/it]\n",
      "Processed prompts: 100%|██████████| 4/4 [00:18<00:00,  4.71s/it]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:21<00:00,  7.20s/it]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:25<00:00,  8.58s/it]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:21<00:00,  7.22s/it]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:26<00:00,  9.00s/it]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.01s/it]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.37s/it]\n"
     ]
    }
   ],
   "source": [
    "output_dataset_name_path = \"pii_dataset\"\n",
    "max_dataset_size = 10\n",
    "\n",
    "terminators = [tokenizer.eos_token]\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, \n",
    "    top_p=0.9, \n",
    "    max_tokens=2058, \n",
    "    skip_special_tokens=True,\n",
    "    stop=terminators\n",
    ")\n",
    "\n",
    "# Generate PII Dataset\n",
    "pii_dataset = generate_pii_dataset(model, tokenizer, sampling_params, essay_dataset['train']['TEXT'], grouped_pii_samples, output_dataset_name_path, max_dataset_size = max_dataset_size)\n",
    "\n",
    "print(f\"\\nFinished Generating PII Dataset with {len(pii_dataset)} samples\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_text': '12 Years a Slave: An Analysis of the Film Essay\\n\\nThe 2013 film 12 Years a Slave proved that slavery is a worldwide issue. Indeed, the film made $150 million outside the United States and $57 million in the U.S., with a production budget of $20 million (Sharf, 2020). The movie was based on the memoir Twelve Years a Slave by Solomon Northup (Ntim, 2020). It tells the story of a free African American man who was kidnapped and sold into slavery. Solomon spent twelve years away from his family, being traded from one master to another. Fortunately, the protagonist met a person who helped him deliver a message to his family and friends, who came and rescued him. This movie accurately illustrates discriminatory relationships between white slaveholders and black slaves that stemmed from the dysfunctional system in the country and prejudices in people’s mindsets at that time. The two main ethnic groups presented in this film are White and African Americans, and the three social groups are affluent slaveholders, working for middle class, and enslaved people. The movie starts with the story of a free African American violinist Solomon Northup, living with his family in Saratoga, New York (McQueen, 2013). However, he was abducted by two white men, who tortured the man and sold him into slavery, changing his name to Plat. Before they met, Solomon and these two slave traders belonged to the same middle class. However, the fact that Northup was an African American made these individuals believe that they had the right to withdraw their freedom. The two masters that Solomon had were William Ford and Edwin Epps (McQueen, 2013). The former was kind and religious, while the latter was cruel and sadistic. Since the movie was based on a real story, it indicated that slaveholders had different characters, but all had the wrong perception of race. Although 12 Years a Slave is a film about slavery, the issues of collectivism and individualism are also raised. Specifically, the main character never identified himself as an enslaved man and continued claiming he was a free citizen (McQueen, 2013). However, his counterparts on the plant had a collective mindset, imprinted in them since childhood, that slavery is normal. These people helped each other because they belonged to the same group. Although Solomon tried to become a part of this community, his individual goal to return home was above the collective values. The movie also showed prejudice, generalizations, stereotyping, and discrimination against black people. For instance, when Ford brings Solomon and Elisa to his plantation, his wife expresses her sadness that Elisa got separated from her children. However, she also stated that “something to eat and some rest” could help that woman forget her children (McQueen, 2013, 32:47-32:51). This scene demonstrated the common prejudice about slaves that they were not capable of the same feelings as white people. An example of generalization and stereotyping was how Tibeats, a carpenter, became hostile to Solomon when he showed his intelligence and gave Ford advice. In fact, Tibeats believed that Plat would never be more competent than any white individual because Plat was a “nigger” (McQueen, 2013, 36:35-36:37). Notably, before Northup became enslaved, he never experienced discrimination, but when the main character was sold into slavery, discrimination was the only attitude that he could observe. In summary, 12 Years a Slave depicts the life of enslaved people and slave owners almost two centuries ago. The film narrates a free black man’s life from the moment when he enjoyed his family’s company in the state of New York to his abduction, enslavement, and eventual liberation. Overall, the movie raised such critical issues as discrimination, prejudice, stereotyping, and generalization that allowed slaveholders to maintain this societal structure for a long time. References\\n\\nMcQueen, S. (2013).',\n",
       " 'pii_text': \"12 Years a Slave: An Analysis of the Film Essay\\n\\nThe 2013 film 12 Years a Slave proved that slavery is a worldwide issue. Indeed, the film made $150 million outside the in just a few weeks, grossing 019847530123598764 The film's success can be attributed to its powerful storytelling, which explores the brutal reality of slavery and its effects on individuals and society, and its cultural relevance and commercial success. United States and $57 million in the U.S., with a production budget of $20 million (Sharf, 2020). The movie was based on the memoir Twelve Years a Slave by Solomon Northup (Ntim, 2020). It and the film's success can be attributed to its marketing strategy, which included a prominent email campaign Elvapattersonsahavi@ho.re by exploring the powerful and emotional story of Solomon Northup, a free African American man who was kidnapped and sold into slavery, and its impact on his life and the lives of those around him, as well as its cultural relevance and commercial success. tells the story of a free African American man who and its impact can be measured through its success, as it grossed SKINNY@bibdivo.su by exploring its historical context and the impact it had on the characters, as well as its commercial success and cultural relevance was kidnapped and sold into slavery. Solomon spent twelve years away from his family, being traded from one master to another. Fortunately, the protagonist met a person who helped him deliver a message to his family and friends, who and received an email from Holt@ginsaufo.es The film's portrayal of the brutal reality of slavery and its effects on individuals and society highlights the significance of understanding and addressing the ongoing struggles of racism and prejudice, which is further emphasized by the fact that came and rescued him. This movie accurately illustrates discriminatory relationships between white slaveholders and black slaves that stemmed from the dysfunctional system in the country and prejudices in people’s The film's success can be attributed to its marketing strategy, which included a prominent email campaign ilpisug@zot.ci The film's portrayal of the brutal reality of slavery and its effects on individuals and society highlights the significance of understanding and addressing the ongoing struggles of racism and prejudice mindsets at that time. The two main ethnic groups presented in this film are White and African Americans, and the three social groups are affluent slaveholders, working for middle class, and enslaved people. The movie starts with the story of a free African American violinist Solomon Northup, living with his and it was directed by 78-47--2-2-5--32-96--5052836 The film's portrayal of the brutal reality of slavery and its effects on individuals and society highlights the significance of understanding and addressing the ongoing struggles of racism and prejudice. family in Saratoga, The film's production budget was a mere $20 million, but it grossed a significant amount, with $150 million earned outside the United States and $57 million in the U.S. 4797_4_350 The film's portrayal of the brutal reality of slavery and its effects on individuals and society highlights the significance of understanding and addressing the ongoing struggles of racism and prejudice. New York (McQueen, 2013). However, he was abducted by two white men, who tortured the man and sold him into slavery, changing his name to Plat. Before they met, Solomon and these two slave traders belonged to the same middle class. However, the fact that Northup was an African American made these individuals believe that who was then sold into slavery with the identification number 13789 The film's portrayal of the brutal reality of slavery and its effects on individuals and society highlights the significance of understanding and addressing the ongoing struggles of racism and prejudice, which is further emphasized by the movie's success in connecting with audiences worldwide. they had the right to withdraw their freedom. The two masters that Solomon had were William Ford and Edwin Epps (McQueen, 2013). The former was kind and religious, while the latter was cruel and sadistic. Since the movie was based on a real story, it indicated that slaveholders had different characters, but all had the wrong perception of race. Although 12 Years a Slave is a film about slavery, the issues of collectivism and individualism are also raised. Specifically, the main character never identified himself as an enslaved man and continued claiming he was a free citizen (McQueen, 2013). However, his counterparts The film's impact can be gauged by its success, as it reached audiences through WAYNEvagjuv@ize.sl by showcasing the struggles and hardships faced by Solomon and other enslaved individuals, the film highlights the devastating consequences of racism and prejudice in the antebellum South. on the plant had a collective mindset, imprinted in them since childhood, that slavery is normal. These people helped each other because they belonged to the same group. Although Solomon tried to become a part of this community, his individual goal to return home was above the collective values. The movie also showed prejudice, generalizations, stereotyping, and discrimination against black people. For instance, when Ford brings Solomon and Elisa to his plantation, his wife expresses her sadness The film's success can be attributed to its ability to connect with audiences worldwide, with a box office gross of $207 million, as identified by the unique 6919978449503183 The film's exploration of the brutal reality of slavery and its effects on individuals and society highlights the significance of understanding and addressing the ongoing struggles of racism and prejudice, which is further emphasized by the movie's success in connecting with audiences worldwide. that Elisa got separated from her children. However, she also stated that “something to eat and some rest” could help that woman forget her The film's success can be attributed to its ability to connect with audiences worldwide, with a phone call to 02 (320 537) 8935203 The film's exploration of the brutal reality of slavery and its effects on individuals and society highlights the significance of understanding and addressing the ongoing struggles of racism and prejudice, which is further emphasized by the movie's success in connecting with audiences worldwide. children (McQueen, 2013, 32:47-32:51). This scene demonstrated the common prejudice about slaves that they were not capable of the same feelings as white people. An example of generalization and stereotyping was how Tibeats, a carpenter, became hostile to Solomon when he showed his intelligence and gave Ford advice. In fact, Tibeats believed that Plat would never be more competent than any white individual because Plat was The film's impact can be gauged by its success, as it reached audiences through a phone call to  (823) 276 3 1564 as it delves into the life of Solomon Northup, a free black man who was kidnapped and sold into slavery, and his struggles to maintain his identity and humanity in the face of brutal treatment and dehumanizing conditions a “nigger” (McQueen, 2013, 36:35-36:37). Notably, before Northup became enslaved, he never experienced discrimination, but when the main character was sold into slavery, discrimination was the only attitude that he could observe. In summary, 12 Years a Slave depicts the life of enslaved people and slave owners almost two centuries ago. The film narrates a free black man’s life from the moment when he enjoyed his family’s company in the state of New York to his abduction, enslavement, and eventual liberation. Overall, the movie raised such critical issues as discrimination, prejudice, stereotyping, and generalization that allowed slaveholders to maintain this societal structure for a long time. References\\n\\nMcQueen, S. (2013).\",\n",
       " 'pii_data': ['WAYNEvagjuv@ize.sl',\n",
       "  '4797_4_350',\n",
       "  '78-47--2-2-5--32-96--5052836',\n",
       "  '6919978449503183',\n",
       "  '02 (320 537) 8935203',\n",
       "  'SKINNY@bibdivo.su',\n",
       "  'Holt@ginsaufo.es',\n",
       "  '13789',\n",
       "  'Elvapattersonsahavi@ho.re',\n",
       "  'ilpisug@zot.ci',\n",
       "  ' (823) 276 3 1564',\n",
       "  '019847530123598764'],\n",
       " 'pii_labels': ['email',\n",
       "  'id_number',\n",
       "  'id_number',\n",
       "  'id_number',\n",
       "  'phone_number',\n",
       "  'email',\n",
       "  'email',\n",
       "  'id_number',\n",
       "  'email',\n",
       "  'email',\n",
       "  'phone_number',\n",
       "  'id_number']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 samples\n",
    "print(\"First 5 samples:\")\n",
    "for i in range(5):\n",
    "    if i >= len(pii_dataset):\n",
    "        break\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"\\nSource Text: {pii_dataset[i]['source_text']}\")\n",
    "    print(f\"\\nPII Text: {pii_dataset[i]['pii_text']}\")\n",
    "    print(f\"\\nPII Data: {pii_dataset[i]['pii_data']}\")\n",
    "    print(f\"\\nPII Labels: {pii_dataset[i]['pii_labels']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 samples\n",
    "print(\"First 5 samples:\")\n",
    "for i in range(5):\n",
    "    if i >= len(pii_dataset):\n",
    "        break\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"\\nSource Text: {pii_dataset[i]['source_text']}\")\n",
    "    print(f\"\\nPII Text: {pii_dataset[i]['pii_text']}\")\n",
    "    print(f\"\\nPII Data: {pii_dataset[i]['pii_data']}\")\n",
    "    print(f\"\\nPII Labels: {pii_dataset[i]['pii_labels']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
